{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "from random import choices\n",
    "\n",
    "# Support for ARM64 Mac Devices\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "import os\n",
    "\n",
    "# Extracts Demo Files from ZIP Archives\n",
    "def extract_demo_files(demo_dir: str = '/Users/mattkingsbury/cs_msc/comp_demos', \n",
    "                       expr_dir: str = '/Users/mattkingsbury/cs_msc/decomp_demos') -> None:\n",
    "    for filename in os.listdir(demo_dir):\n",
    "        if filename.endswith('.zip'):\n",
    "            zip_path = os.path.join(demo_dir, filename)\n",
    "            with zf.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(expr_dir)\n",
    "\n",
    "extract_demo_files()\n",
    "demoNames = [fileName for fileName in os.listdir('/Users/mattkingsbury/cs_msc/decomp_demos') if fileName.endswith('dem')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awpy import DemoParser\n",
    "from awpy.analytics.stats import player_stats\n",
    "\n",
    "# Parses a Demo File into a .json File\n",
    "def parser(file: str) -> Tuple[str, any]:\n",
    "    fpath = '/Users/mattkingsbury/cs_msc/decomp_demos/'\n",
    "    id = ''.join(choices(file, k = 12))\n",
    "    demo_parser = DemoParser(\n",
    "        demofile = fpath + file, \n",
    "        demo_id = id, \n",
    "        parse_rate = 128, \n",
    "        trade_time = 5, \n",
    "        buy_style = \"hltv\"\n",
    "    )\n",
    "\n",
    "    demo = demo_parser.parse()\n",
    "    return (id, demo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import arr_to_dict, euclidean_distance, add_trajectory\n",
    "\n",
    "# Retrieves Statistics and Player Trajectories for a Match\n",
    "def get_team_stats_and_trajectories(demo_and_id: Tuple[str, any]) -> Dict[str, Tuple[List[float], List[float]]]:\n",
    "    (id, demo) = demo_and_id\n",
    "    teams: List[str] = [None, None]\n",
    "    team1_stats: List[float] = [0.] * 14\n",
    "    team2_stats: List[float] = [0.] * 14\n",
    "    num_rounds: int = 0\n",
    "\n",
    "    # Player Stats\n",
    "    stats_per_player: Dict = player_stats(demo['gameRounds'])\n",
    "    for stats in stats_per_player.values():\n",
    "        num_rounds = max(num_rounds, stats['totalRounds'])\n",
    "        curr_player_team = stats['teamName']\n",
    "        clutch_successes: List[float] = sum([\n",
    "            stats['success1v1'], \n",
    "            stats['success1v2'], \n",
    "            stats['success1v3'], \n",
    "            stats['success1v4'], \n",
    "            stats['success1v5']])\n",
    "        clutch_attempts: List[float] = sum([\n",
    "            stats['attempts1v1'], \n",
    "            stats['attempts1v2'], \n",
    "            stats['attempts1v3'], \n",
    "            stats['attempts1v4'], \n",
    "            stats['attempts1v5']])\n",
    "        curr_player_stats: List[float] = [ \n",
    "            stats['kills'], # Kills\n",
    "            sum([stats['kills2'], stats['kills3'], stats['kills4'], stats['kills5']]), # Multi-Kills\n",
    "            stats['firstKills'], # Entry-Kills\n",
    "            stats['totalDamageGiven'], # Damage Dealt\n",
    "            stats['totalDamageTaken'], # Damage Taken\n",
    "            stats['hsPercent'], # Player Headshot Percentage\n",
    "            stats['plants'], # Times Player Planted Bomb\n",
    "            stats['defuses'], # Times Player Defused Bomb\n",
    "            stats['flashAssists'], # Count Enemies Flashed + Killed By Team While Blind\n",
    "            stats['smokesThrown'], # Count Smokes Thrown\n",
    "            stats['utilityDamage'], # Total Damage Enemies Received From Player Utility (Grenades, Molotovs)\n",
    "            stats['tradeKills'], # Times Player Killed Enemy Immediately After Enemy Killed Teammate\n",
    "            clutch_successes / clutch_attempts if clutch_attempts > 0 else None, # Clutch Conversion Probability\n",
    "            stats['teamKills'] + stats['suicides'] # Sum (Player Killed Teammate, Player Killed Self) \n",
    "        ]\n",
    "\n",
    "        # Separate Stats by Team\n",
    "        if teams[0] == None or teams[0] == curr_player_team: \n",
    "            teams[0] = curr_player_team\n",
    "            team1_stats = [None if x is None or y is None else x + y for x, y in zip(curr_player_stats, team1_stats)]\n",
    "        elif teams[1] == None or teams[1] == curr_player_team:\n",
    "            teams[1] = curr_player_team\n",
    "            team2_stats = [None if x is None or y is None else x + y for x, y in zip(curr_player_stats, team2_stats)]\n",
    "\n",
    "    # Sum Team Stats for Bomb and Kill Events\n",
    "    sum_team1_time_to_plant, team1_num_plants, sum_team1_kills_dist, team1_num_kills = 0, 0, 0, 0\n",
    "    sum_team2_time_to_plant, team2_num_plants, sum_team2_kills_dist, team2_num_kills = 0, 0, 0, 0\n",
    "    trajectories:  Dict[str, Dict[int, List[Tuple[float, float]]]] = {}\n",
    "\n",
    "    # Number of Seconds to Analyse Trajectories\n",
    "    seconds: int = (lambda x: x if x > 3 else 3)(12)\n",
    "    for round in demo['gameRounds']:\n",
    "        for bombEvent in round['bombEvents']:\n",
    "            if bombEvent['bombAction'] == 'plant':\n",
    "                if bombEvent['playerTeam'] == teams[0]:\n",
    "                    sum_team1_time_to_plant += bombEvent['seconds']\n",
    "                    team1_num_plants += 1\n",
    "                else:\n",
    "                    sum_team2_time_to_plant += bombEvent['seconds']\n",
    "                    team2_num_plants += 1\n",
    "                break\n",
    "        for killEvent in round['kills']:\n",
    "            if killEvent['attackerTeam'] == teams[0]:\n",
    "                sum_team1_kills_dist += euclidean_distance(\n",
    "                    (killEvent['attackerX'], killEvent['attackerY'], killEvent['attackerZ']),\n",
    "                    (killEvent['victimX'], killEvent['victimY'], killEvent['victimZ'])\n",
    "                )\n",
    "                team1_num_kills += 1\n",
    "            else:\n",
    "                sum_team2_kills_dist += euclidean_distance(\n",
    "                    (killEvent['attackerX'], killEvent['attackerY'], killEvent['attackerZ']),\n",
    "                    (killEvent['victimX'], killEvent['victimY'], killEvent['victimZ'])\n",
    "                )\n",
    "                team2_num_kills += 1\n",
    "        for frames in round['frames']:\n",
    "            if frames['seconds'] >= seconds:\n",
    "                break\n",
    "            for team in ['t', 'ct']:\n",
    "                for player in frames[team]['players']:\n",
    "                    position: Tuple[float, float] = (player['x'], player['y'])\n",
    "                    key: str = player['name'] + ':' + str(player['steamID'])\n",
    "                    add_trajectory(\n",
    "                        key, \n",
    "                        round['roundNum'], \n",
    "                        position, \n",
    "                        trajectories\n",
    "                    )\n",
    "\n",
    "    # Avg Time For Team To Plant Per Round\n",
    "    avg_team1_plant_time: float = None if team1_num_plants == 0 else sum_team1_time_to_plant / team1_num_plants\n",
    "    avg_team2_plant_time: float = None if team2_num_plants == 0 else sum_team2_time_to_plant / team2_num_plants\n",
    "\n",
    "    # Avg Distance Per Kill For Each Team\n",
    "    avg_team1_kills_dist: float = None if team1_num_kills == 0 else sum_team1_kills_dist / team1_num_kills\n",
    "    avg_team2_kills_dist: float = None if team2_num_kills == 0 else sum_team2_kills_dist / team2_num_kills\n",
    "\n",
    "    # Calculate Avg Team Statistics\n",
    "    team1_stats_pr: List[float] = [\n",
    "        *(None if stat is None else stat / num_rounds for stat in team1_stats),\n",
    "        avg_team1_plant_time,\n",
    "        avg_team1_kills_dist,\n",
    "    ]\n",
    "\n",
    "    team2_stats_pr: List[float] = [\n",
    "        *(None if stat is None else stat / num_rounds for stat in team2_stats),\n",
    "        avg_team2_plant_time,\n",
    "        avg_team2_kills_dist\n",
    "    ]\n",
    "\n",
    "    round_win_ratio = (0, 0)\n",
    "    for round in demo['gameRounds']:\n",
    "        winningIndex = int(round['winningTeam'] == teams[1])\n",
    "        round_win_ratio[winningIndex] += 1\n",
    "\n",
    "    # Return Access to Relevant Data\n",
    "    return {\n",
    "        \"demo\": id,\n",
    "        \"stats\": (team1_stats_pr, team2_stats_pr),\n",
    "        \"trajectories\": trajectories,\n",
    "        \"rounds\": num_rounds,\n",
    "        \"round_win_ratio\": round_win_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract Cluster Labels\n",
    "def cluster(algorithm) -> Tuple[Dict[int, int], np.ndarray]:\n",
    "    labels = algorithm.labels_\n",
    "    strategy_map: Dict[int, int] = arr_to_dict(labels) \n",
    "    return (strategy_map, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_clusters(trajectories_list: List[np.ndarray], labels: List[str]):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Cluster Colours\n",
    "    unique_labels = sorted(set(labels))\n",
    "    colors = plt.colormaps.get_cmap('tab20')\n",
    "\n",
    "    enumerate_labels = list(enumerate(labels))\n",
    "    for (trajectory, (i, label)) in zip(trajectories_list, enumerate_labels):\n",
    "        if i % 2 != 0: # Plot every other trajectory\n",
    "            continue\n",
    "        if label == -1:\n",
    "            color = 'k'\n",
    "            label_text = 'No Group'\n",
    "        else:\n",
    "            color = colors(unique_labels.index(label))\n",
    "            label_text = f'Group {label}'\n",
    "        plt.plot(trajectory[:, 0], \n",
    "                trajectory[:, 1], \n",
    "                color = color,\n",
    "                alpha = 0.5, \n",
    "                label = label_text if label_text not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "    # Titles and Display Plot\n",
    "    plt.xlabel('x Coordinate')\n",
    "    plt.ylabel('y Coordinate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Data for All Parsed Demos\n",
    "all_matches_data = {}\n",
    "for file in demoNames:\n",
    "    demo = parser(file)\n",
    "    data = get_team_stats_and_trajectories(demo)\n",
    "    all_matches_data[data['demo']] = {\n",
    "        't': data['trajectories'],\n",
    "        's': data['stats'],\n",
    "        'n': data['rounds'],\n",
    "        'r': data['round_win_ratio']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Data for Clustering\n",
    "trajectories_list: List[np.ndarray] = []\n",
    "targets_for_regression = []\n",
    "round_player_info: Dict[Tuple[int, str], List[Tuple[int, str]]] = {}\n",
    "for match in all_matches_data:\n",
    "    num_rounds = all_matches_data[match]['n']\n",
    "    for player in all_matches_data[match]['t']:\n",
    "        for round_num, trajectory in all_matches_data[match]['t'][player].items():\n",
    "            trajectories_list.append(np.array(trajectory))\n",
    "            key = (num_rounds, match)\n",
    "            if key not in round_player_info:\n",
    "                round_player_info[key] = []\n",
    "            round_player_info[key].append((round_num, player))\n",
    "    for target_point in all_matches_data[match]['r']:\n",
    "        targets_for_regression.append(target_point / num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "\n",
    "# Compute the DTW distance matrix\n",
    "num_trajectories = len(trajectories_list)\n",
    "dtw_mtx = np.zeros((num_trajectories, num_trajectories))\n",
    "for i in range(num_trajectories):\n",
    "    for j in range(i + 1, num_trajectories):\n",
    "        distance, _ = fastdtw(trajectories_list[i], trajectories_list[j])\n",
    "        dtw_mtx[i, j] = distance\n",
    "        dtw_mtx[j, i] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Perform Agglomerative Clustering for Individual Trajectories\n",
    "cluster_agglomerative = AgglomerativeClustering(\n",
    "    n_clusters = 12,\n",
    "    linkage = 'average',\n",
    "    metric = 'precomputed'\n",
    ").fit(dtw_mtx)\n",
    "\n",
    "(agg_strategies_map, agg_labels) = cluster(cluster_agglomerative)\n",
    "plot_clusters(trajectories_list, agg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "cluster_dbscan = DBSCAN(\n",
    "    eps = 2750, \n",
    "    min_samples = 8, \n",
    "    metric = 'precomputed',\n",
    ").fit(dtw_mtx)\n",
    "\n",
    "(db_strategies_map, db_labels) = cluster(cluster_dbscan)\n",
    "plot_clusters(trajectories_list, db_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "# Perform OPTICS clustering\n",
    "cluster_optics = OPTICS(\n",
    "    cluster_method = 'dbscan',\n",
    "    eps = 2800, \n",
    "    min_samples = 5, \n",
    "    metric = 'precomputed'\n",
    ").fit(dtw_mtx)\n",
    "\n",
    "(opt_strategies_map, opt_labels) = cluster(cluster_optics)\n",
    "plot_clusters(trajectories_list, opt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Cluster Labels to Player Trajectories\n",
    "all_trajectories_per_game_per_team = []\n",
    "for match_id in round_player_info:\n",
    "    mid = len(round_player_info[match_id]) // 2\n",
    "    t1_data = round_player_info[match_id][:mid] # Team 1 Occupies the first half of the data\n",
    "    t2_data = round_player_info[match_id][mid:] # Team 2 Occupies the second half of the data\n",
    "    if t1_data[0][0] != 1 or t2_data[0][0] != 1:\n",
    "        raise Exception(\"Data has not split correctly.\")\n",
    "    t1_round_trajectories = {}\n",
    "    t2_round_trajectories = {}\n",
    "    label_list = agg_labels.tolist()\n",
    "    for (round_number, _) in t1_data:\n",
    "        if round_number not in t1_round_trajectories:\n",
    "            t1_round_trajectories[round_number] = []\n",
    "        t1_round_trajectories[round_number].append(label_list.pop(0))\n",
    "    for (round_number, _) in t2_data:\n",
    "        if round_number not in t2_round_trajectories:\n",
    "            t2_round_trajectories[round_number] = []\n",
    "        t2_round_trajectories[round_number].append(label_list.pop(0))\n",
    "    all_trajectories_per_game_per_team.append(list(t1_round_trajectories.values()))\n",
    "    all_trajectories_per_game_per_team.append(list(t2_round_trajectories.values()))\n",
    "print(\"- - -Example Trajectories for a Team on a Singular Map- - -\")\n",
    "print(\"Array: [A, B, C, D, E] Represents Initial Trajectories of a Team in a Given Round\")\n",
    "print(\"Values: The Cluster Label for the input Trajectory (the Grouping)\")\n",
    "all_trajectories_per_game_per_team[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from helpers import jaccard_distance\n",
    "\n",
    "flat_trajectories_sets: List[set] = []\n",
    "for arr in all_trajectories_per_game_per_team:\n",
    "    flat_trajectories_sets += map(set, arr)\n",
    "\n",
    "jaccards = pairwise_distances(\n",
    "    flat_trajectories_sets, \n",
    "    metric = jaccard_distance\n",
    ")\n",
    "\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters = 10,\n",
    "    metric = 'precomputed', \n",
    "    linkage = 'complete'\n",
    ")\n",
    "\n",
    "labels = clustering.fit_predict(jaccards)\n",
    "print(\"Team Strategy Labels per Round\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "map_vals: Dict[int, List] = {}\n",
    "for team_openings in all_trajectories_per_game_per_team:\n",
    "    for opening_strat in team_openings:\n",
    "        label = labels[i].astype(int)\n",
    "        if label not in map_vals:\n",
    "            map_vals[label] = []\n",
    "        map_vals[label].append(sorted(opening_strat, reverse = True))\n",
    "        i += 1\n",
    "\n",
    "for k, v in map_vals.items():\n",
    "    print(\"Cluster\", str(k) + \": \", str(len(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from helpers import jaccard_distance\n",
    "\n",
    "# Calculates Avg. Similarity across All Clusters\n",
    "def calculate_average_similarity(clusters: Dict[int, List]) -> Tuple[Dict, float]:\n",
    "    cluster_similarities = {}\n",
    "    all_similarities = []\n",
    "    for cluster_id, elements in clusters.items():\n",
    "        if len(elements) < 2:\n",
    "            cluster_similarities[cluster_id] = None\n",
    "            continue\n",
    "\n",
    "        pairwise_similarities = [\n",
    "            (1 - jaccard_distance(set(el1), set(el2))) for el1, el2 in combinations(elements, 2)\n",
    "        ]\n",
    "        cluster_avg_similarity = np.mean(pairwise_similarities)\n",
    "        cluster_similarities[cluster_id] = cluster_avg_similarity\n",
    "        all_similarities.extend(pairwise_similarities)\n",
    "    \n",
    "    overall_average_similarity = np.mean(all_similarities) if all_similarities else None\n",
    "    return (cluster_similarities, overall_average_similarity)\n",
    "\n",
    "# Calculate and print the similarities\n",
    "cluster_similarities, overall_average_similarity = calculate_average_similarity(map_vals)\n",
    "print(\"Jaccard Similarities:\")\n",
    "for cluster_id, similarity in cluster_similarities.items():\n",
    "    print(f\"Cluster {cluster_id}: {similarity:.2f}\" if similarity is not None else f\"Cluster {cluster_id}: Not enough elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import hamming_distance\n",
    "\n",
    "# Calculates Avg. Similarity across All Clusters\n",
    "def calculate_hamming_similarity(clusters: Dict[int, List]) -> Tuple[Dict, float]:\n",
    "    cluster_similarities = {}\n",
    "    all_similarities = []\n",
    "    for cluster_id, elements in clusters.items():\n",
    "        if len(elements) < 2:\n",
    "            cluster_similarities[cluster_id] = None\n",
    "            continue\n",
    "\n",
    "        pairwise_similarities = [\n",
    "            hamming_distance(sorted(el1), sorted(el2)) for el1, el2 in combinations(elements, 2)\n",
    "        ]\n",
    "        cluster_avg_similarity = np.mean(pairwise_similarities)\n",
    "        cluster_similarities[cluster_id] = cluster_avg_similarity\n",
    "        all_similarities.extend(pairwise_similarities)\n",
    "    \n",
    "    overall_average_similarity = np.mean(all_similarities) if all_similarities else None\n",
    "    return (cluster_similarities, overall_average_similarity)\n",
    "\n",
    "# Calculate and print the similarities\n",
    "cluster_similarities, overall_average_similarity = calculate_hamming_similarity(map_vals)\n",
    "print(\"Hamming Distances:\")\n",
    "for cluster_id, similarity in cluster_similarities.items():\n",
    "    print(f\"Cluster {cluster_id}: {similarity:.2f}\" if similarity is not None else f\"Cluster {cluster_id}: Not enough elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_for_regression = []\n",
    "li_labels = list(labels)\n",
    "for arr in all_trajectories_per_game_per_team:\n",
    "    strategies_employed = [0] * len(map_vals.keys())\n",
    "    for i in range(len(arr)):\n",
    "        strategies_employed[li_labels.pop(0)] += 1\n",
    "    strategies_for_regression.append([x / len(arr) for x in strategies_employed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_regression = []\n",
    "for k, v in all_matches_data.items():\n",
    "    data_for_regression.append(v['s'][0])\n",
    "    data_for_regression.append(v['s'][1])\n",
    "\n",
    "for row in data_for_regression:\n",
    "    row += strategies_for_regression.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data_for_regression)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_regression[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msccode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
